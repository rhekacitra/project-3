<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Comparing Surgical Approaches Across Time, BMI, Blood Loss, Mortality, and Age</title>
  <script src="https://d3js.org/d3.v7.min.js"></script>
  <link rel="stylesheet" href="style.css" />
  <style>
    #tooltip {
      position: absolute;
      background: rgba(255, 255, 255, 0.9);
      border: 1px solid #ccc;
      padding: 8px;
      font-size: 12px;
      pointer-events: none;
      display: none;
      box-shadow: 2px 2px 5px rgba(0,0,0,0.2);
    }
  </style>
</head>
<body>
  <h2>Comparing Surgical Approaches Across Time, BMI, Blood Loss, Mortality, and Age</h2>

  <div class="controls">
    <label><input type="checkbox" value="Robotic" checked> Robotic</label>
    <label><input type="checkbox" value="Videoscopic" checked> Videoscopic</label>
    <label><input type="checkbox" value="Open" checked> Open</label>
  </div>

  <div class="container">
    <svg id="chart" width="1500" height="750"></svg>
  </div>

  <div class="legend-wrapper">
    <div class="legend" id="legend"></div>
  </div>

  <div id="tooltip"></div>

    <div class="text">
    <section>
      <h2>Design Rationale</h2>      
      <p><strong>Visual Encoding:</strong></p>
      <ul>
        <li>This visualization is created based on the <a href="https://vitaldb.net/dataset/">VitalDB Korean Surgery Dataset</a>. Given the growing trend toward minimally invasive techniques, particularly robotic and video-assisted surgeries, it is crucial to understand how these approaches compare in practice. By focusing on the surgical approach, we can explore how these modern methods impact patient outcomes and interact with other key variables. That's why we chose different surgical approaches (robotic, video-assisted, open) that require varying techniques and resources, which might affect factors such as surgery time, BMI, blood loss, mortality rate, and age.</li>
        <li>We selected a parallel coordinate plot as the primary visualization type because it is well-suited for displaying trends across multiple continuous variables (e.g., surgery time, BMI, blood loss, mortality rate, and age).</li>
        <li>Due to the class imbalance in the surgical approach, we chose a bright red color for the robotic approach to make it stand out against the other methods. This ensures that the robotic approach does not get overshadowed by the larger datasets of the video-assisted and open approaches.</li>
      </ul>

      <p><strong>Interaction:</strong></p>
      <ul>
        <li>We implemented filtering options using buttons that allow users to view only the data relevant to their interests, specifically surgical approaches (robotic, video, open). This reduces visual clutter and helps users focus on specific subsets of data.</li>
        <li>Tooltips were created to highlight individual data points when a user hovers over them, making it easier for users to track specific lines across the plot and gain a deeper understanding of the data.</li>
        <li>We also added a brushing tool that enables users to select specific ranges of data by dragging a selection box over the plot. This allows users to zoom in on particular subsets of data (e.g., specific ranges of surgery time, BMI, or blood loss), dynamically updating the plot to focus on selected data. This feature enhances user interaction, enabling users to explore specific trends more interactively.</li>
        <li>Additionally, each time the filtering options are changed, the data is randomly sampled to ensure that other data points may be included, providing a more diverse and representative view each time. This approach helps keep the data dynamic and prevents it from being fixed to a single subset, allowing users to see different patterns based on their selection.</li>
      </ul>
      
      <p><strong>Data Transformation:</strong></p>
      <ul>
        <li>Data reduction and binning: We implemented data reduction techniques to enhance visibility and avoid overcrowding the graph. By simplifying the data presentation, we ensured that users can easily discern patterns without being overwhelmed by excessive details. This includes binning the data to group similar values and make comparisons more intuitive.</li>
        <li>Handling extreme outliers: The feature <code>'Death in Hospital'</code> shows only one value (0) because we filtered the data to include only the middle 50th percentile of blood loss. This decision was made due to the presence of extreme outliers in the blood loss data, which caused the scale to be extremely large. Filtering the data allowed us to better visualize the trends and make the plot more interpretable. We suspect that extreme blood loss cases were likely associated with patients who passed away.</li>
      </ul>
    </section>
    
    <section>
      <h2>Development Process</h2>
      <p>The development process began with a brainstorming session where we discussed various interactions and features to include in the visualization. This involved deciding on elements such as tooltips for better user experience, filtering buttons to allow for customizable data exploration, and choices around color schemes to make the data visually clear and distinguishable. We also deliberated on the most appropriate visualization type to represent the data, ultimately deciding on a parallel coordinates plot for its ability to show multi-dimensional trends.</p>
            
      <p>The entire development process took approximately 5 hours. The most time-consuming part of the project was building and refining the parallel coordinates plot. This involved configuring the axes, incorporating interactive features, and ensuring the data was correctly mapped to the visualization. The addition of the brushing tool required extra time for integration and testing to ensure smooth interaction with the rest of the plot. The other tasks, including adding tooltips, implementing the filtering buttons, and deploying the site, were quicker and smoother once the visualization type was in place.</p>
      
      <p>The work was divided among three team members:</p>
      <ul>
        <li><strong>Viki Shi</strong> and <strong>Katrina Suherman</strong>: were primarily responsible for the final visualization. Their tasks included adding interactive design elements (e.g., tooltips, filtering options, and the brushing feature), transforming the data into the correct format for the plot, and finalizing the color scheme for the different surgical approaches.</li>
        <li><strong>Rheka Narwastu</strong>: focused on deploying the web page, ensuring it was accessible online, and providing answers to two key write-up questions.</li>
      </ul>
    </section>
    
    

  </div>

  <script>
    const svg = d3.select("#chart");
    const width = +svg.attr("width");
    const height = +svg.attr("height");

    const margin = { top: 30, right: 60, bottom: 10, left: 60 };
    const innerWidth = width - margin.left - margin.right;
    const innerHeight = height - margin.top - margin.bottom;

    const colorMap = {
      Robotic: "#e63946",
      Open: "#a8cfff",
      Videoscopic: "#78c679"
    };

    const line = d3.line();
    const g = svg.append("g").attr("transform", `translate(${margin.left},${margin.top})`);

    let allData, yScale, xScale;
    let brushingNow = false;

    const dimensions = [
      { key: "surgery_time_hours", label: "Surgery Time (hours)" },
      { key: "bmi", label: "BMI (kg/mÂ²)" },
      { key: "intraop_ebl", label: "Blood Loss (mL)" },
      { key: "death_inhosp", label: "Death in Hospital" },
      { key: "age", label: "Age (years)" }
    ];

    const tooltip = d3.select("#tooltip");

    d3.json("cases_filtered.json").then(data => {
      data.forEach((d, i) => d._id = i);
      allData = data;

      const approachCounts = d3.rollup(
        allData,
        v => v.length,
        d => d.approach
      );

      const legendDiv = d3.select("#legend");
      Array.from(approachCounts.entries()).forEach(([approach, count]) => {
        legendDiv.append("div")
          .attr("class", "legend-item")
          .html(`
            <span class="legend-color" style="background:${colorMap[approach]}"></span>
            <span>${approach}: ${count}</span>
          `);
      });

      yScale = {};
      dimensions.forEach(({ key }) => {
        const values = allData.map(p => +p[key]);
        yScale[key] = d3.scaleLinear()
          .domain(d3.extent(values))
          .range([innerHeight, 0]);
      });

      xScale = d3.scalePoint()
        .domain(dimensions.map(d => d.label))
        .range([0, innerWidth]);

      const gAxis = g.selectAll(".axis")
        .data(dimensions)
        .join("g")
        .attr("class", "axis")
        .attr("transform", d => `translate(${xScale(d.label)},0)`)
        .each(function(d) {
          d3.select(this).call(d3.axisLeft(yScale[d.key]));
        });

      gAxis.append("text")
        .attr("y", -9)
        .attr("x", 0)
        .attr("text-anchor", "middle")
        .attr("fill", "black")
        .style("font-size", "12px")
        .text(d => d.label);

      drawLines(getSelectedApproaches());
      addBrushes();

      // Clear brushes when clicking outside
      d3.select("body").on("click", function (event) {
        const isBrushClick = event.target.closest(".brush");
        if (!isBrushClick && !brushingNow) {
          g.selectAll(".brush").each(function () {
            d3.select(this).call(d3.brush().clear);
          });
          drawLines(getSelectedApproaches());
        }
      });
    });

    function drawLines(approaches) {
      const filtered = approaches.flatMap(approach => {
        const subset = allData.filter(d => d.approach === approach);
        const count = Math.max(1, Math.floor(subset.length * 0.1));
        return d3.shuffle(subset).slice(0, count);
      });

      filtered.sort((a, b) => {
        const order = { Open: 0, Videoscopic: 1, Robotic: 2 };
        return order[a.approach] - order[b.approach];
      });

      drawFilteredLines(filtered);
    }

    function drawFilteredLines(data) {
      let pathGroup = g.select("g.foreground");
      if (pathGroup.empty()) {
        pathGroup = g.append("g").attr("class", "foreground");
      }

      const paths = pathGroup.selectAll("path")
        .data(data, d => d._id);

      paths.join(
        enter => enter.append("path")
          .attr("d", d => line(dimensions.map(p => [xScale(p.label), yScale[p.key](+d[p.key])])))
          .attr("class", d => `approach-${d.approach.toLowerCase()}`)
          .attr("stroke", d => colorMap[d.approach])
          .attr("fill", "none")
          .attr("stroke-width", 1.5)
          .on("mouseover", function(event, d) {
            d3.select(this).attr("stroke-width", 3);
            tooltip.style("display", "block")
              .html(`
                <strong>Surgery Time:</strong> ${d.surgery_time_hours} hrs<br/>
                <strong>BMI:</strong> ${d.bmi}<br/>
                <strong>Blood Loss:</strong> ${d.intraop_ebl} mL<br/>
                <strong>Death in Hospital:</strong> ${d.death_inhosp ? "Yes" : "No"}<br/>
                <strong>Age:</strong> ${d.age} yrs
              `);
          })
          .on("mousemove", function(event) {
            tooltip.style("left", (event.pageX + 10) + "px")
                   .style("top", (event.pageY - 28) + "px");
          })
          .on("mouseout", function() {
            d3.select(this).attr("stroke-width", 1.5);
            tooltip.style("display", "none");
          }),
        update => update,
        exit => exit.remove()
      );
    }

    function addBrushes() {
      g.selectAll(".brush").remove();

      dimensions.forEach(({ key, label }) => {
        const brush = d3.brushY()
          .extent([[ -10, 0 ], [ 10, innerHeight ]])
          .on("start", () => brushingNow = true)
          .on("end", function(event) {
            brushingNow = false;
            brushed(event);
          });

        g.append("g")
          .attr("class", "brush")
          .attr("transform", `translate(${xScale(label)},0)`)
          .call(brush);
      });

      function brushed(event) {
        const activeFilters = new Map();

        g.selectAll(".brush")
          .each(function(d, i) {
            const selection = d3.brushSelection(this);
            const key = dimensions[i].key;
            if (selection) {
              const [y0, y1] = selection;
              activeFilters.set(key, [yScale[key].invert(y1), yScale[key].invert(y0)]);
            }
          });

        const selectedApproaches = getSelectedApproaches();
        const filtered = allData.filter(d => {
          if (!selectedApproaches.includes(d.approach)) return false;

          for (const [dim, [min, max]] of activeFilters) {
            const val = +d[dim];
            if (val < min || val > max) return false;
          }
          return true;
        });

        drawFilteredLines(filtered);
      }
    }

    function getSelectedApproaches() {
      return Array.from(document.querySelectorAll(".controls input:checked"))
                  .map(input => input.value);
    }

    d3.selectAll(".controls input").on("change", function () {
      drawLines(getSelectedApproaches());
    });
  </script>
</body>
</html>
